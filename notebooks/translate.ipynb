{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24216012",
   "metadata": {},
   "source": [
    "# Traduzindo dataset com o Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9726e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea27d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def load_yaml_config(file_path='../translator.prompt.yml'):\n",
    "    \"\"\"\n",
    "    Carrega o arquivo YAML e retorna como um dicionário\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "# Carrega a configuração do YAML\n",
    "translator_config = load_yaml_config()\n",
    "\n",
    "print(\"Chaves disponíveis no config:\")\n",
    "for key in translator_config.keys():\n",
    "    print(f\"- {key}\")\n",
    "    print(f\"  Tipo: {type(translator_config.get(key))}\")\n",
    "\n",
    "print(f\"\\nModelo: {translator_config.get('model')}\")\n",
    "print(f\"Temperatura: {translator_config.get('modelParameters', {}).get('temperature')}\")\n",
    "print(f\"Número de mensagens: {len(translator_config.get('messages', []))}\")\n",
    "print(f\"Role da primeira mensagem: {translator_config.get('messages', [{}])[0].get('role')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046191a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '../data/SMSSpamCollectionDataset.csv',\n",
    "    on_bad_lines='skip',\n",
    "    encoding='latin1'\n",
    ")\n",
    "\n",
    "df = df[['label', 'text']]\n",
    "df['translated_text'] = None\n",
    "df.info()\n",
    "print(\"\\nDistribuição dos labels:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError(\"A chave de API GEMINI_API_KEY não está definida no ambiente.\")\n",
    "base_url = os.getenv('GEMINI_BASE_URL')\n",
    "if not base_url:\n",
    "    raise ValueError(\"A URL base GEMINI_BASE_URL não está definida no ambiente.\")\n",
    "llm_model = os.getenv('LLM_MODEL'))\n",
    "\n",
    "translator = OpenAI(\n",
    "    api_key=os.getenv('GEMINI_API_KEY'),\n",
    "    base_url=os.getenv('GEMINI_BASE_URL')\n",
    ")\n",
    "print(\"=== OpenAI client configurado com sucesso. ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(row):\n",
    "    \"\"\"\n",
    "    Traduz o texto usando a configuração do YAML\n",
    "    \"\"\"\n",
    "\n",
    "    # print(f\"Tipo: {row['label']}\")\n",
    "    if pd.isna(row['translated_text']):\n",
    "        try:\n",
    "            translated_response = translator.chat.completions.create(\n",
    "                model='gemma3:1b',\n",
    "                temperature=translator_config.get('modelParameters').get('temperature'),\n",
    "                messages=[\n",
    "                    {\n",
    "                        'role': translator_config.get('messages')[0].get('role'),\n",
    "                        'content': translator_config.get('messages')[0].get('content')\n",
    "                    },\n",
    "                    {\n",
    "                        'role': translator_config.get('messages')[1].get('role'),\n",
    "                        'content': translator_config.get('messages')[1].get('content').replace('{{text}}', row['text'])\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            translated_text = translated_response.choices[0].message.content\n",
    "            # print(f\"Texto original: {row['text']}\")\n",
    "            # print(f\"Texto traduzido: {translated_text}\")\n",
    "            # print(\"-\" * 50)\n",
    "\n",
    "            row['translated_text'] = translated_text\n",
    "\n",
    "        except Exception as e:\n",
    "            # print(f\"Erro ao traduzir o texto: {row['text']}\")\n",
    "            # print(f\"ERRO: {e}\")\n",
    "            # print(\"-\" * 50)\n",
    "            row['translated_text'] = None\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "df = df.progress_apply(translate_text, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
